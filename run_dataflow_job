# set up workbench environment to be able to use numbs....requires cuda 11.3 so  Apache Beam notebooks will not work


#fixed a lot of issues with dockerfile by building locally
docker build -t pytorchbase -f Dockerfile.pytorch .
docker image tag pytorchbase us-central1-docker.pkg.dev/cool-machine-learning/rw-dataflow/pytorchbase
docker image push  us-central1-docker.pkg.dev/cool-machine-learning/rw-dataflow/pytorchbase


docker history --no-trunc us-central1-docker.pkg.dev/cool-machine-learning/axlearn/maingpu:nondf  | tac | tr -s ' ' | cut -d " " -f 5- | sed 's,^/bin/sh -c #(nop) ,,g' | sed 's,^/bin/sh -c,RUN,g' | sed 's, && , \\\n  & ,g' | sed 's,\s*[0-9]*[\.]*[0-9]*\s*[kMG]*B\s*$,,g' | head -n -1
docker history --no-trunc us-central1-docker.pkg.dev/cool-machine-learning/axlearn/maingpu:core  | tac | tr -s ' ' | cut -d " " -f 5- | sed 's,^/bin/sh -c #(nop) ,,g' | sed 's,^/bin/sh -c,RUN,g' | sed 's, && , \\\n  & ,g' | sed 's,\s*[0-9]*[\.]*[0-9]*\s*[kMG]*B\s*$,,g' | head -n -1



#run job on dataflow

​​docker run --rm  --mount type=bind,src=$HOME/.config/gcloud,dst=/root/.config/gcloud \
--entrypoint /bin/bash us-central1-docker.pkg.dev/cool-machine-learning/axlearn/axlearn-dataflow:remyw-6a14d7 \
-c "python3 -m apache_beam.examples.wordcount --input=gs://dataflow-samples/shakespeare/kinglear.txt --output=gs://dataflow-test-bucket0/rwtest/output/ --runner=DataflowRunner --project=cool-machine-learning --region=us-west1 --temp_location=gs://dataflow-test-bucket0/rwtest/temp/ --staging_location=gs://dataflow-test-bucket0/rwtest/staging --service_account_email=ml-training@cool-machine-learning.iam.gserviceaccount.com"

#with GPU (works but doesnt use GPU)
run --rm  --mount type=bind,src=$HOME/.config/gcloud,dst=/root/.config/gcloud \
--entrypoint /bin/bash us-central1-docker.pkg.dev/cool-machine-learning/axlearn/axlearn-dataflow:remyw-6a14d7 \
-c "python3 -m apache_beam.examples.wordcount \
 --input=gs://dataflow-samples/shakespeare/kinglear.txt \
  --output=gs://dataflow-test-bucket0/rwtest/output/ \
   --runner=DataflowRunner --project=cool-machine-learning \
   --worker_machine_type=n1-highmem-16 \
   --disk_size_gb=50 \
   --dataflow_service_options='worker_accelerator=type:nvidia-tesla-t4;count:1;install-nvidia-driver' \
   --experiments=use_runner_v2 \
    --region=us-west1 --temp_location=gs://dataflow-test-bucket0/rwtest/temp/ \
     --staging_location=gs://dataflow-test-bucket0/rwtest/staging \
      --service_account_email=ml-training@cool-machine-learning.iam.gserviceaccount.com"

#with GPU workload
docker build -t us-central1-docker.pkg.dev/cool-machine-learning/axlearn/maingpu:nondf .
docker push us-central1-docker.pkg.dev/cool-machine-learning/axlearn/maingpu:nondf

docker run --rm  --mount type=bind,src=$HOME/.config/gcloud,dst=/root/.config/gcloud \
--entrypoint /bin/bash us-central1-docker.pkg.dev/cool-machine-learning/axlearn/maingpu:core \
-c "python3 -m axlearn.cloud.gcp.examples.mainGPU \
--sdk_container_image=us-central1-docker.pkg.dev/cool-machine-learning/axlearn/maingpu:core \
--sdk_location=container \
--project=cool-machine-learning \
--region=us-west1 \
--temp_location=gs://dataflow-test-bucket0/rwtest/temp/ \
--staging_location=gs://dataflow-test-bucket0/rwtest/staging \
   --disk_size_gb=50 \
   --runner=DataflowRunner \
   --worker_machine_type=n1-standard-16 \
   --dataflow_service_options=\"worker_accelerator=type:nvidia-tesla-t4;count:1;install-nvidia-driver\" \
   --experiments=use_runner_v2 \
      --service_account_email=ml-training@cool-machine-learning.iam.gserviceaccount.com"

--sdk_container_image=us-central1-docker.pkg.dev/cool-machine-learning/axlearn/maingpu:core \
--sdk_location=container
sdk_container_image="us-central1-docker.pkg.dev/cool-machine-learning/axlearn/maingpu:core", sdk_location=container

#attempt 9/17, updating TF and using regular pyproject.toml, also updated maingpu to print tf version
docker run --rm  --mount type=bind,src=$HOME/.config/gcloud,dst=/root/.config/gcloud \
--entrypoint /bin/bash us-central1-docker.pkg.dev/cool-machine-learning/axlearn/axlearn-dataflow:newtf1 \
-c "python3 -m axlearn.cloud.gcp.examples.mainGPU \
--name=remyw-newtf-gpuoptions \
--sdk_container_image=us-central1-docker.pkg.dev/cool-machine-learning/axlearn/axlearn-dataflow:newtf1 \
--sdk_location=container \
--project=cool-machine-learning \
--region=us-west1 \
--temp_location=gs://dataflow-test-bucket0/rwtest/temp/ \
--staging_location=gs://dataflow-test-bucket0/rwtest/staging \
   --disk_size_gb=50 \
   --runner=DataflowRunner \
   --worker_machine_type=n1-standard-16 \
   --dataflow_service_options='worker_accelerator=type:nvidia-tesla-t4;count:1;install-nvidia-driver' \
   --experiments=use_runner_v2 \
      --service_account_email=ml-training@cool-machine-learning.iam.gserviceaccount.com"


#9/20...trying with downgraded versions---works!
docker run --rm  --mount type=bind,src=$HOME/.config/gcloud,dst=/root/.config/gcloud \
--entrypoint /bin/bash us-central1-docker.pkg.dev/cool-machine-learning/axlearn/axlearn-dataflow:cuda118 \
-c "python3 -m axlearn.cloud.gcp.examples.mainGPU \
--name=remyw-newtf-gpuoptions \
--sdk_container_image=us-central1-docker.pkg.dev/cool-machine-learning/axlearn/axlearn-dataflow:cuda118 \
--sdk_location=container \
--project=cool-machine-learning \
--region=us-west1 \
--temp_location=gs://dataflow-test-bucket0/rwtest/temp/ \
--staging_location=gs://dataflow-test-bucket0/rwtest/staging \
   --disk_size_gb=50 \
   --runner=DataflowRunner \
   --worker_machine_type=n1-standard-16 \
   --dataflow_service_options='worker_accelerator=type:nvidia-tesla-t4;count:1;install-nvidia-driver' \
   --experiments=use_runner_v2 \
      --service_account_email=ml-training@cool-machine-learning.iam.gserviceaccount.com"


#10/8...trying again with python 3.8 image - works!
docker run --rm  --mount type=bind,src=$HOME/.config/gcloud,dst=/root/.config/gcloud \
--entrypoint /bin/bash us-central1-docker.pkg.dev/cool-machine-learning/rw-dataflow/cu118v3 \
-c "python3 -m axlearn.cloud.gcp.examples.mainGPU \
--name=remyw-newtf-gpuoptions \
--sdk_container_image=us-central1-docker.pkg.dev/cool-machine-learning/rw-dataflow/cu118v3 \
--sdk_location=container \
--project=cool-machine-learning \
--region=us-west1 \
--temp_location=gs://dataflow-test-bucket0/rwtest/temp/ \
--staging_location=gs://dataflow-test-bucket0/rwtest/staging \
   --disk_size_gb=50 \
   --runner=DataflowRunner \
   --worker_machine_type=n1-standard-16 \
   --dataflow_service_options='worker_accelerator=type:nvidia-tesla-t4;count:1;install-nvidia-driver' \
   --experiments=use_runner_v2 \
      --service_account_email=ml-training@cool-machine-learning.iam.gserviceaccount.com"

#trying python10
docker run --rm  --mount type=bind,src=$HOME/.config/gcloud,dst=/root/.config/gcloud \
--entrypoint /bin/bash us-central1-docker.pkg.dev/cool-machine-learning/rw-dataflow/py10rapids \
-c "python3 -m axlearn.cloud.gcp.examples.mainGPU \
--sdk_container_image=us-central1-docker.pkg.dev/cool-machine-learning/rw-dataflow/py10rapids \
--sdk_location=container \
--project=cool-machine-learning \
--region=us-west1 \
--temp_location=gs://dataflow-test-bucket0/rwtest/temp/ \
--staging_location=gs://dataflow-test-bucket0/rwtest/staging \
   --disk_size_gb=50 \
   --runner=DataflowRunner \
   --worker_machine_type=n1-standard-16 \
   --dataflow_service_options='worker_accelerator=type:nvidia-tesla-t4;count:1;install-nvidia-driver:5xx' \
   --experiments=use_runner_v2 \
      --service_account_email=ml-training@cool-machine-learning.iam.gserviceaccount.com"


#new python-based image
docker run --rm  --mount type=bind,src=$HOME/.config/gcloud,dst=/root/.config/gcloud \
--entrypoint /bin/bash us-central1-docker.pkg.dev/cool-machine-learning/rw-dataflow/df-gemini \
-c "python3 -m axlearn.cloud.gcp.examples.mainGPU \
--sdk_container_image=us-central1-docker.pkg.dev/cool-machine-learning/rw-dataflow/df-gemini \
--sdk_location=container \
--project=cool-machine-learning \
--region=us-west1 \
--temp_location=gs://dataflow-test-bucket0/rwtest/temp/ \
--staging_location=gs://dataflow-test-bucket0/rwtest/staging \
   --disk_size_gb=50 \
   --runner=DataflowRunner \
   --worker_machine_type=n1-standard-16 \
   --dataflow_service_options='worker_accelerator=type:nvidia-tesla-t4;count:1;install-nvidia-driver' \
   --experiments=use_runner_v2 \
      --service_account_email=ml-training@cool-machine-learning.iam.gserviceaccount.com"


#pytorch
docker run --rm  --mount type=bind,src=$HOME/.config/gcloud,dst=/root/.config/gcloud \
--entrypoint /bin/bash us-central1-docker.pkg.dev/cool-machine-learning/rw-dataflow/pytorchdf \
-c "python3 -m axlearn.cloud.gcp.examples.pytorchpipeline \
--input_data=gs://apache-beam-ml/testing/inputs/openimage_50k_benchmark.txt \
--output_data=gs://temp-storage-for-end-to-end-tests/torch/result_gpu_xqhu.txt \
--model_state_dict_path=gs://apache-beam-ml/models/torchvision.models.mobilenet_v2.pth \
--model_name=mobilenet_v2 \
--sdk_container_image=us-central1-docker.pkg.dev/cool-machine-learning/rw-dataflow/pytorchdf \
--sdk_location=container \
--project=cool-machine-learning \
--region=us-west1 \
--temp_location=gs://dataflow-test-bucket0/rwtest/temp/ \
--staging_location=gs://dataflow-test-bucket0/rwtest/staging \
   --disk_size_gb=50 \
   --runner=DataflowRunner \
   --worker_machine_type=n1-standard-16 \
   --dataflow_service_options='worker_accelerator=type:nvidia-tesla-t4;count:1;install-nvidia-driver' \
   --experiments=use_runner_v2 \
      --service_account_email=ml-training@cool-machine-learning.iam.gserviceaccount.com"


   
# axlearn dataflow on CPU - works completely now!
# Dockerfile and pyproject.toml should be the same as the one in the main axlearn branch, 
# but in case that gets updated and breaks something, use Dockerfile.axl in my dataflow branch:
# https://github.com/remylouisew/axlearn/tree/dataflow
DOCKER_REPO=us-central1-docker.pkg.dev/cool-machine-learning/axlearn
DOCKER_IMAGE=remyw-4dbe38

axlearn gcp dataflow start \
    --name=$USER-dataflow \
    --bundler_spec=extras=dataflow \
    --bundler_spec=dockerfile=Dockerfile \
    --bundler_spec=target=dataflow \
    --bundler_spec=allow_dirty=True \
    --bundler_spec=image=${DOCKER_IMAGE} \
    --bundler_spec=repo=${DOCKER_REPO} \
    --dataflow_spec=runner=DataflowRunner \
    --dataflow_spec=region=us-central2 \
    --dataflow_spec=machine_type=n2-standard-8 \
    -- "'
    python3 -m apache_beam.examples.wordcount \
            --input=gs://dataflow-samples/shakespeare/kinglear.txt \
        --output=gs://ttl-30d-us-central2/axlearn/users/remyw/dataflow/wordcount'"